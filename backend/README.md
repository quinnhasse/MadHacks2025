# Transparens AI - Backend

Backend API server for Transparens AI, providing transparent AI answers with evidence graphs.

## Architecture

The backend implements a clean separation between:

1. **Research Agent** (`services/researchAgent.ts`) - Uses Exa API to fetch relevant sources
2. **Answer Agent** (`services/answerAgent.ts`) - Uses LLM to generate answers ONLY from provided sources
3. **Evidence Graph Builder** (`services/evidenceGraph.ts`) - Constructs a graph linking questions â†’ answer blocks â†’ sources

## Setup

### Prerequisites

- Node.js 18+
- npm or pnpm

### Installation

```bash
cd backend
npm install
```

### Environment Variables

Create a `.env` file in the `backend/` directory:

```env
EXA_API_KEY=your_exa_api_key_here
LLM_API_KEY=your_llm_api_key_here
PORT=3001
NODE_ENV=development
```

**Required API Keys:**
- `EXA_API_KEY` - Get from [Exa](https://exa.ai/)
- `LLM_API_KEY` - OpenAI API key for answer generation (get from [OpenAI](https://platform.openai.com/api-keys))

### Running the Server

Development mode (with hot reload):
```bash
npm run dev
```

Production build:
```bash
npm run build
npm start
```

Type checking:
```bash
npm run type-check
```

Testing:
```bash
# Test research agent (Exa integration)
npm run test:research

# Test answer agent (OpenAI integration)
npm run test:answer

# Test evidence graph builder (Phase 4)
npm run test:graph
```

## API Endpoints

### POST /api/answer

Ask a question and receive a structured answer with sources and evidence graph.

**Request:**
```json
{
  "question": "What is AI transparency?"
}
```

**Response:**
```json
{
  "question": "What is AI transparency?",
  "answer": {
    "text": "Full answer text...",
    "blocks": [
      {
        "id": "ans-1",
        "type": "paragraph",
        "text": "AI transparency refers to...",
        "source_ids": ["s1", "s3"]
      }
    ]
  },
  "sources": [
    {
      "id": "s1",
      "title": "Source Title",
      "url": "https://example.com",
      "snippet": "Relevant excerpt...",
      "score": 0.95
    }
  ],
  "evidence_graph": {
    "nodes": [
      {
        "id": "q",
        "type": "question",
        "label": "What is AI transparency?",
        "metadata": { "layer": 0 }
      },
      {
        "id": "answer",
        "type": "answer_root",
        "label": "AI transparency refers to the ability to understand...",
        "metadata": { "layer": 0 }
      },
      {
        "id": "ans-1",
        "type": "answer_block",
        "label": "AI transparency refers to...",
        "metadata": { "layer": 1 }
      },
      {
        "id": "s1",
        "type": "source",
        "label": "Source Title",
        "metadata": { "layer": 2, "citationCount": 1 }
      }
    ],
    "edges": [
      { "from": "q", "to": "answer", "relation": "answers" },
      { "from": "answer", "to": "ans-1", "relation": "answers" },
      { "from": "ans-1", "to": "s1", "relation": "supports" }
    ],
    "metadata": {
      "sourceCount": 1,
      "blockCount": 1
    }
  },
  "meta": {
    "model": "gpt-4o-mini",
    "retrieval_latency_ms": 500,
    "answer_latency_ms": 2500,
    "graph_latency_ms": 5,
    "total_latency_ms": 3005
  }
}
```

### GET /health

Health check endpoint.

**Response:**
```json
{
  "status": "ok",
  "timestamp": "2025-11-22T12:00:00.000Z",
  "environment": "development"
}
```

## Project Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # Server entry point
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ env.ts            # Environment configuration
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ answerRoute.ts    # /api/answer endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ researchAgent.ts  # Exa-based source retrieval
â”‚   â”‚   â”œâ”€â”€ answerAgent.ts    # LLM-based answer generation
â”‚   â”‚   â””â”€â”€ evidenceGraph.ts  # Evidence graph builder
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ shared.ts         # TypeScript type definitions
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

## Current Status

### âœ… Phase 1: Project Setup (Complete)
- Complete TypeScript type system
- Express server with CORS and logging
- Full API endpoint structure
- Evidence graph generation

### âœ… Phase 2: Exa Research Agent (Complete)
- **Full Exa API integration** in `researchAgent.ts`
- Optimized for RAG use cases with:
  - 5 high-quality sources per query
  - Full text content (up to 10,000 characters)
  - Highlights/snippets (3 sentences, 5 per URL)
  - Relevance scoring
- Graceful error handling with stub fallback
- Safe API key management
- Test harness for unit testing (`npm run test:research`)
- Integration with `/api/answer` endpoint

### âœ… Phase 3: LLM Answer Agent (Complete)
- **Full OpenAI integration** in `answerAgent.ts`
- Answer generation ONLY from provided sources (no hallucination)
- Structured answer blocks with explicit source citations
- Comprehensive validation and error handling
- Uses GPT-4o-mini model for fast, cost-effective responses
- JSON mode for guaranteed structured output
- Retry logic with exponential backoff
- Graceful fallback when LLM unavailable
- Test harness for unit testing (`npm run test:answer`)

### âœ… Phase 4: Evidence Graph with Answer Root Node (Complete)
- **Answer-centric graph topology** - Answer at center, not question
- Graph structure designed for 3D visualization:
  - **Layer 0 (Center):** Answer root node + Question node (side connection)
  - **Layer 1:** Answer blocks radiating from center
  - **Layer 2:** Sources at periphery
- New node type: `answer_root` (central node representing complete answer)
- Edge relationships:
  - `question â†’ answer_root` (answers relation)
  - `answer_root â†’ blocks` (answers relation)
  - `blocks â†’ sources` (supports relation)
- Smart features:
  - Label truncation at word boundaries for readability
  - Citation count metadata on source nodes
  - Edge deduplication (same source cited multiple times)
  - Layer metadata for 3D positioning
  - Full text preservation in node metadata
- Validation and error handling:
  - GraphBuildError for structural issues
  - Warnings (not failures) for missing source references
  - Duplicate ID detection
- Test harness: `npm run test:graph`

### âœ… Phase 5: Production Hardening & DX (Complete)
- **Comprehensive error handling** in `/api/answer`:
  - Research failures: Continue with empty sources, log error, mark degraded
  - Answer failures: Use fallback answer, preserve partial data
  - Graph failures: Return minimal graph (question node only)
  - **Never crashes server** - graceful degradation for all failures
- **Detailed logging** with ISO timestamps:
  - Request start with question text
  - Per-phase logging (research, answer, graph)
  - Source counts and retrieval latency
  - Answer length, block count, and generation latency
  - Graph node/edge counts broken down by type
  - Total latency with percentage breakdown
  - Error tracking with detailed messages
- **Security:** No API keys or full_text in logs
- **Enhanced response metadata:**
  - `graph_latency_ms` - Time to build evidence graph
  - `degraded` flag - Indicates partial failure
  - `errors` array - Detailed error messages for debugging

### ðŸš§ Future Enhancements
- Rate limiting
- Caching layer for repeated queries
- Advanced graph metrics (centrality, clustering)
- Performance optimizations

## Development Notes

### Exa Integration

The `researchAgent.ts` now includes full Exa API integration:

**Request Configuration:**
- Endpoint: `https://api.exa.ai/search`
- Authentication: `x-api-key` header
- Search parameters optimized for RAG:
  - `numResults: 5` - Quality over quantity
  - `type: 'auto'` - Let Exa choose best search method (neural vs deep)
  - `text.maxCharacters: 10000` - Full content for LLM context
  - `highlights` - Concise snippets for quick reference

**Error Handling:**
- Missing API key â†’ Falls back to stub sources with warning
- Network errors â†’ Falls back to stub sources with error log
- API errors â†’ Parses error response and falls back gracefully

**Response Mapping:**
- Maps Exa results to `Source` type
- Generates sequential IDs (`s1`, `s2`, etc.)
- Extracts snippets from highlights or text preview
- Preserves metadata (published date, author, scores, etc.)

### Testing

**Unit Testing:**
Run the research agent test harness:
```bash
npm run test:research
```

This tests the agent with multiple sample questions and validates:
- Source structure (id, title, url, snippet, score)
- API integration (if EXA_API_KEY is set)
- Stub fallback (if EXA_API_KEY is missing)
- Error handling

**Integration Testing:**
Test the full pipeline via the API:
```bash
# Start the server
npm run dev

# In another terminal, test with curl
curl -X POST http://localhost:3001/api/answer \
  -H "Content-Type: application/json" \
  -d '{"question": "What is Transparens AI?"}'
```

### Answer Agent Implementation

The Answer Agent (`answerAgent.ts`) uses OpenAI's GPT-4o-mini model to generate source-grounded answers:

**Key Features:**
1. **Source Grounding:** Answers ONLY use information from provided sources
2. **JSON Mode:** Uses OpenAI's `response_format: { type: "json_object" }` for guaranteed structure
3. **Prompt Engineering:**
   - System message establishes strict "no hallucination" rules
   - User message includes formatted sources with IDs, titles, URLs, and content
   - Clear JSON schema specification
4. **Validation:**
   - Validates answer structure (text, blocks, source_ids)
   - Verifies all source_ids reference actual sources
   - Filters out invalid source citations
5. **Error Handling:**
   - Retry logic (2 attempts) with exponential backoff
   - Fallback to safe stub answer on failure
   - Never crashes the /api/answer endpoint
6. **Performance:**
   - Smart source truncation (1000 chars per source)
   - Total context budget (30,000 chars)
   - Average latency: 2-6 seconds
   - Token usage: ~1,000-1,500 tokens per request

**Model Configuration:**
- Model: `gpt-4o-mini` (fast, cost-effective)
- Temperature: `0.3` (factual, deterministic)
- Max tokens: `3000` (sufficient for multi-block answers)

**Testing:**
Run the answer agent test suite:
```bash
npm run test:answer
```

This validates:
- Answer structure (AnswerPayload type)
- Source attribution (all source_ids are valid)
- Grounding (blocks cite actual sources)
- Error handling (empty sources, API failures)
